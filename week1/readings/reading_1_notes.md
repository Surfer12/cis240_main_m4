


2.2. REPRESENTING NUMBERS ON COMPUTERS101111111+ 00110111111+ 0011(a) (b)(610)(310)(310)Carry digits(610)(310)(310)Carry digitsFigure 2.4: Adding two three-bit binary numbers. (a) Dashed arrows indicate where the carry out comesfrom. (b) Simpliﬁed representation (without arrows).Figure 2.5 illustrates the subtraction of two three-bit unsigned binary numbers. Figure 2.5 (b) showsthe ﬁrst step, in which the least signiﬁcant digits are subtracted. Since “1” cannot be subtracted from“0”, some value must be borrowed from the left column. The “*” character indicates that value had tobe borrowed from the left column. The result in this column is “1”, since “10” (two) minus “1” (one) is“1”. Figure 2.5 (c) illustrates the operation on the second least signiﬁcant digit. Since the right columnborrowed from this column, the ﬁrst operand is now “0”. Again, since “1” cannot be subtracted from“0”, some value must be borrowed from the left column. The result in this column is “1”, since “10”(two) minus “1” (one) is “1”. Figure 2.5 (d) shows the subtraction of the most signiﬁcant digits (zerominus zero) and the ﬁnal result. Figure 2.5 (e) shows a simpliﬁed representation of the subtraction.1011- 01(a)(310)(610)1110110- 01*(b)(310)(610)11101110- 010**(c)(310)(610)111011100- 010**(d)(310)(310)(610)1101110- 01**(e)(310)(310)(610)Figure 2.5: Subtraction of two three-bit binary numbers. (a) The digits of both numbers are alignedon columns. (b) First, the least signiﬁcant digits are subtracted - the “*” character indicates that somevalue was borrowed from the left column. (c) The second least signiﬁcant digits are subtracted - again,the “*” character indicates that some value was borrowed from the left column. (d) Finally, the mostsigniﬁcant digits are subtracted producing digit “0”. (e) Simpliﬁed representation of the subtraction.2.2.4 Integer overﬂowAn integer overﬂow occurs when the result of an arithmetic operation on two integer m-bit binarynumbers is outside the range that can be represented by an m-bit binary number. Figure 2.6 shows anexample in which the addition of two three-bit unsigned binary numbers causes an integer overﬂow. Inthis case, adding one to seven should result in eight, however, the value eight cannot be representedusing only three bits on the unsigned binary representation.Printed version available for purchase at Amazon.comFree online version at http://riscv-programming.org(Generated on August 28, 2024)16
2.3. REPRESENTING TEXT1 1 1 ← carry digits0 0 1 (110)+ 1 1 1 (710)0 0 0 (010)Figure 2.6: Example of an integer overﬂow on the unsigned binary representation. The result of one plusseven cannot be represented by a three-bit unsigned binary number.Even though the operation illustrated on Figure 2.6 characterizes an integer overﬂow on the unsignedbinary representation, it does not characterize an integer overﬂow on the signed (two’s complement)binary representation. In this case, the operation is adding one (001) to minus one5(111) and theexpected result, i.e., zero, can be represented by a three-bit unsigned binary number.Figure 2.7 shows an example in which the addition of two three-bit signed binary numbers using thetwo’s complement method causes an integer overﬂow. In this case, however, there was no integer overﬂowon the unsigned binary number representation. Notice that the result of the operation is as expected,i.e., four (100), on the unsigned binary representation.1 1 ← carry digits0 1 1 (310)+ 0 0 1 (110)1 0 0 (−410)Figure 2.7: Example of an integer overﬂow on the signed binary representation. The result of three plusone cannot be represented by a three-bit signed binary number using the two’s complement representa-tion.2.3 Representing textA character is the basic unit of information when representing text on computers and usually correspondsto a letter (e.g., “a”), a decimal digit (e.g., “2”), a punctuation mark (e.g., “.” or “?”), white spaces, oreven a control information6.The character encoding standard deﬁnes how characters are represented on computers.For example, the American Standard Code for Information Interchange, or ASCII, deﬁnes thatcharacters are represented by seven-bit numbers. Table 2.6 shows a subset of the characters encoded bythe American Standard Code for Information Interchange. Notice that the letter “a” is encoded as thenumber 9710(1100012) while digit “2” is encoded as the number 5010(01100102).The ASCII character encoding standard was designed in the 1960s and, even though it included mostsymbols used on the English language, it lacked several important symbols required by other languages,such letters with accents (e.g., “´a”, “¸c”, ...). In this context, several other character encoding standardswere introduced, including an extension to the ASCII standard, the “Extended ASCII”, or EASCII.Accordingly to Google7, in 2008 the UTF-8 character encoding standard became the most commonencoding for HTML ﬁles. As of 2020, a survey performed by the W3Techs web site8indicated that morethan 95.5% of the world wide web websites are encoded with the UTF-8 character encoding standard.The “Unicode (or Universal Coded Character Set) Transformation Format - 8-bit”, or UTF-8 forshort, is a variable-width character encoding standard. In this standard, each character may be repre-sented by one, two, three, or four bytes, i.e., one, two, three, or four 8-bit numbers. Common characters,5Notice that the three-bit sequence 111 represents the value minus one on the two’s complement representation.6Control characters are not intended to represent printable information. A line feed, carrier return and backspace areexamples of control characters on computers.7https://googleblog.blogspot.com/2008/05/moving-to-unicode-51.html8https://w3techs.com/technologies/overview/character_encodingPrinted version available for purchase at Amazon.comFree online version at http://riscv-programming.org(Generated on August 28, 2024)17
2.4. ORGANIZING DATA ON THE MEMORYBinary Hex. Dec. Char....0100001221163310!0100010222163410”...010110022C164410,010110122D164510-010111022E164610.010111122F164710/011000023016481000110001231164910101100102321650102...0111000238165610801110012391657109...Binary Hex. Dec. Char.1000001241166510A1000010242166610B...1011001259168910Y101101025A169010Z...1100001261169710a1100010262169810b...11110012791612110y111101027A1612210z...111110027C1612410|111110127D1612510}111111027E1612610˜Table 2.6: Subset of the characters encoded by the ASCII character encoding standard. Hex. and Dec.columns show the encoding value in hexadecimal and decimal representation while the Char. columnshows the symbol encoded by the character.such as letters “a”, “b”, and “c”, are represented by a single byte, while more exotic ones are representedusing multiple bytes. The euro currency sign (¤), for example, is encoded using three bytes: 111000102,100000102, and 101011002.The UTF-8 standard was designed to be backward compatible with the ASCII standard. Hence,ASCII characters are represented on the UTF-8 standard using a single byte with the same value. Forexample, letter “a” is represented by value ninety seven in both standards. In this way, a softwaredesigned to work with the UTF-8 standard can naturally open and handle ASCII encoded ﬁles.Texts are represented in computers as sequences of characters on memory. For example,the word “Yes” is represented by a sequence of three characters (“Y”, “e”, and “s”) stored on consecutivememory positions. In case the ASCII character encoding standard is being used, the three consecutivememory positions will contain values 12110, 10110, and 11510, respectively. Figure 2.8 illustrates howthe word “ma¸c˜a”9is represented in three diﬀerent character encoding standards: the UTF-8, the ISO-LATIN-1 and the Mac OS Roman. Each square represents a byte and the values inside the squares arein hexadecimal. Notice that the UTF-8 standard requires two bytes to represent letter “¸c” and two bytesto represent letter “˜a”.61 E7 E3M a ç ãISO-LATIN-14D 61 8D 8BM a ç ãMac OS Roman4D 61 C3 A7M aç ãUTF-84D C3 A3Figure 2.8: Word “ma¸c˜a” represented in three diﬀerent character encoding standards: the UTF-8, theISO-LATIN-1 and the Mac OS Roman